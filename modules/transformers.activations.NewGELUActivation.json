{
  "class_name": "transformers.activations.NewGELUActivation",
  "kernels": [
    {
      "kernel_type": "basic",
      "operation": "Element-wise power (input³)",
      "analysis": "Computes input³ for each element using torch.pow(input, 3.0). Each power operation requires 2 FLOPs (x * x * x). The input tensor has {num_elements} total elements. This reads the input tensor and writes the pow result.",
      "flops": "2 * {num_elements}",
      "memory_access": {
        "read": "{num_elements} * {a_bytes}",
        "write": "{num_elements} * {a_bytes}"
      }
    },
    {
      "kernel_type": "basic",
      "operation": "Element-wise multiplication by scalar 0.044715",
      "analysis": "Multiplies each element of the pow result by constant 0.044715. This is an element-wise operation on {num_elements} elements, requiring 1 FLOP per element. Reads the pow result and writes the scaled result.",
      "flops": "{num_elements}",
      "memory_access": {
        "read": "{num_elements} * {a_bytes}",
        "write": "{num_elements} * {a_bytes}"
      }
    },
    {
      "kernel_type": "basic",
      "operation": "Element-wise addition (input + scaled_pow_result)",
      "analysis": "Adds the original input to the scaled pow result element-wise. This is an element-wise operation on {num_elements} elements, requiring 1 FLOP per element. Reads both input tensors and writes the sum result.",
      "flops": "{num_elements}",
      "memory_access": {
        "read": "2 * {num_elements} * {a_bytes}",
        "write": "{num_elements} * {a_bytes}"
      }
    },
    {
      "kernel_type": "basic",
      "operation": "Element-wise multiplication by constant sqrt(2/π)",
      "analysis": "Multiplies the sum result by constant sqrt(2/π) ≈ 0.7978845608. This is an element-wise operation on {num_elements} elements, requiring 1 FLOP per element. Reads the sum result and writes the scaled result.",
      "flops": "{num_elements}",
      "memory_access": {
        "read": "{num_elements} * {a_bytes}",
        "write": "{num_elements} * {a_bytes}"
      }
    },
    {
      "kernel_type": "basic",
      "operation": "Hyperbolic tangent activation",
      "analysis": "Computes tanh(x) for each element using torch.tanh(). tanh is typically computed as (exp(x) - exp(-x)) / (exp(x) + exp(-x)), requiring approximately 5 FLOPs per element (2 exp, 2 additions, 1 division). This is an element-wise operation on {num_elements} elements. Reads the scaled sum result and writes the tanh result.",
      "flops": "5 * {num_elements}",
      "memory_access": {
        "read": "{num_elements} * {a_bytes}",
        "write": "{num_elements} * {a_bytes}"
      }
    },
    {
      "kernel_type": "basic",
      "operation": "Element-wise addition with scalar 1.0",
      "analysis": "Adds 1.0 to each element of the tanh result. This is an element-wise operation on {num_elements} elements, requiring 1 FLOP per element. Reads the tanh result and writes the shifted result.",
      "flops": "{num_elements}",
      "memory_access": {
        "read": "{num_elements} * {a_bytes}",
        "write": "{num_elements} * {a_bytes}"
      }
    },
    {
      "kernel_type": "basic",
      "operation": "Element-wise multiplication by scalar 0.5",
      "analysis": "Multiplies the original input by 0.5. This is an element-wise operation on {num_elements} elements, requiring 1 FLOP per element. Reads the input tensor again and writes the half input result.",
      "flops": "{num_elements}",
      "memory_access": {
        "read": "{num_elements} * {a_bytes}",
        "write": "{num_elements} * {a_bytes}"
      }
    },
    {
      "kernel_type": "basic",
      "operation": "Final element-wise multiplication",
      "analysis": "Multiplies the half input by the shifted tanh result element-wise. This is the final operation producing the NewGELU activation output. This is an element-wise operation on {num_elements} elements, requiring 1 FLOP per element. Reads both intermediate tensors and writes the final output.",
      "flops": "{num_elements}",
      "memory_access": {
        "read": "2 * {num_elements} * {a_bytes}",
        "write": "{num_elements} * {a_bytes}"
      }
    }
  ]
}